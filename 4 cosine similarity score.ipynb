{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV: CALCULATION OF COSINE SIMILARITY\n",
    "\n",
    "This section focuses entirely on calculating the cosine similarity between the participant data and the job ads data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **load module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nessesary libraries.\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import gpustat\n",
    "import warnings\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse import hstack\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **check computational environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOWS VERSION: Windows-10-10.0.22631-SP0\n",
      "PYTHON VERSION: 3.11.4 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 13:38:37) [MSC v.1916 64 bit (AMD64)]\n",
      "CPU CORE: 4\n",
      "CPU SPEED: scpufreq(current=2496.0, min=0.0, max=2496.0)\n",
      "GPU: NVIDIA GeForce GTX 1650\n",
      "RAM: 31.87 GB\n",
      "HARD DRIVE: 237.45 GB\n"
     ]
    }
   ],
   "source": [
    "# List the software and hardware configurations used for conducting the experiment.\n",
    "print('WINDOWS VERSION:', platform.platform())\n",
    "print('PYTHON VERSION:', sys.version)\n",
    "print('CPU CORE:', psutil.cpu_count(logical=False))\n",
    "print('CPU SPEED:', psutil.cpu_freq())\n",
    "print('GPU:', gpustat.new_query().gpus[0].name)\n",
    "print(f'RAM: {psutil.virtual_memory().total/(1024 ** 3):.2f} GB')\n",
    "print(f\"HARD DRIVE: {psutil.disk_usage('/').total/(1024 ** 3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **load dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*job seekers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the joob seekers' data frame is: (3, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>preferred_position</th>\n",
       "      <th>education</th>\n",
       "      <th>skill</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-17 15:30:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>bachelor's degree: critical care nursing</td>\n",
       "      <td>patient care, wound care, medical procedures, ...</td>\n",
       "      <td>registered nurse: 3 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-27 11:50:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>electrician</td>\n",
       "      <td>high school diploma, vocational electrician ce...</td>\n",
       "      <td>circuit testing, blueprint reading, fault find...</td>\n",
       "      <td>residential electrician's helper: 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3</td>\n",
       "      <td>google form</td>\n",
       "      <td>2023-12-31 13:39:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>degree: master of science in data analytics, b...</td>\n",
       "      <td>python, data mining and extraction, data analy...</td>\n",
       "      <td>entry level data analyst: 1 year; data coordin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant data_collection                 date         location  \\\n",
       "0      user_1      voice call  2023-12-17 15:30:00  dublin, ireland   \n",
       "1      user_2      voice call  2023-12-27 11:50:00  dublin, ireland   \n",
       "2      user_3     google form  2023-12-31 13:39:00  dublin, ireland   \n",
       "\n",
       "  preferred_position                                          education  \\\n",
       "0   registered nurse           bachelor's degree: critical care nursing   \n",
       "1        electrician  high school diploma, vocational electrician ce...   \n",
       "2       data analyst  degree: master of science in data analytics, b...   \n",
       "\n",
       "                                               skill  \\\n",
       "0  patient care, wound care, medical procedures, ...   \n",
       "1  circuit testing, blueprint reading, fault find...   \n",
       "2  python, data mining and extraction, data analy...   \n",
       "\n",
       "                                          experience  \n",
       "0                          registered nurse: 3 years  \n",
       "1           residential electrician's helper: 1 year  \n",
       "2  entry level data analyst: 1 year; data coordin...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the experiment participants dataset.\n",
    "df_jobseeker = pd.read_csv('data_jobseeker.csv', index_col=None)\n",
    "print(\"The shape of the joob seekers' data frame is:\", df_jobseeker.shape)\n",
    "\n",
    "df_jobseeker.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset consists of 3 rows and 8 columns of data collected from experiment participants through interviews. The last three columns in this DataFrame (DF), which contain text data on education, skill, and experience, are intended to be used for analysis. Calculating the cosine score for each column individually is impractical and illogical. Therefore, it is necessary to combine these columns into a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>preferred_position</th>\n",
       "      <th>combined_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-17 15:30:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>bachelor's degree: critical care nursing. pati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-27 11:50:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>electrician</td>\n",
       "      <td>high school diploma, vocational electrician ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3</td>\n",
       "      <td>google form</td>\n",
       "      <td>2023-12-31 13:39:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>degree: master of science in data analytics, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant data_collection                 date         location  \\\n",
       "0      user_1      voice call  2023-12-17 15:30:00  dublin, ireland   \n",
       "1      user_2      voice call  2023-12-27 11:50:00  dublin, ireland   \n",
       "2      user_3     google form  2023-12-31 13:39:00  dublin, ireland   \n",
       "\n",
       "  preferred_position                                      combined_info  \n",
       "0   registered nurse  bachelor's degree: critical care nursing. pati...  \n",
       "1        electrician  high school diploma, vocational electrician ce...  \n",
       "2       data analyst  degree: master of science in data analytics, b...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply minor modifications for further use.\n",
    "df_jobseeker['combined_info'] = df_jobseeker.education + '. ' + df_jobseeker.skill + '. ' + df_jobseeker.experience + '.'\n",
    "df_jobseeker.drop(['education', 'skill', 'experience'], axis=1, inplace=True)\n",
    "\n",
    "df_jobseeker.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having merged the text data into a single column, it is essential to perform a word count. This step will guide us in determining the appropriate approach for processing this text in the subsequent analytical stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>preferred_position</th>\n",
       "      <th>combined_info</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-17 15:30:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>bachelor's degree: critical care nursing. pati...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-27 11:50:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>electrician</td>\n",
       "      <td>high school diploma, vocational electrician ce...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3</td>\n",
       "      <td>google form</td>\n",
       "      <td>2023-12-31 13:39:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>degree: master of science in data analytics, b...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant data_collection                 date         location  \\\n",
       "0      user_1      voice call  2023-12-17 15:30:00  dublin, ireland   \n",
       "1      user_2      voice call  2023-12-27 11:50:00  dublin, ireland   \n",
       "2      user_3     google form  2023-12-31 13:39:00  dublin, ireland   \n",
       "\n",
       "  preferred_position                                      combined_info  \\\n",
       "0   registered nurse  bachelor's degree: critical care nursing. pati...   \n",
       "1        electrician  high school diploma, vocational electrician ce...   \n",
       "2       data analyst  degree: master of science in data analytics, b...   \n",
       "\n",
       "   word_count  \n",
       "0          27  \n",
       "1          33  \n",
       "2          60  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the word count for each ad and add its values to a new column.\n",
    "df_jobseeker['word_count'] = df_jobseeker['combined_info'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df_jobseeker.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*job ads*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the joob ads' data frame is: (1166, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>registered nurse</td>\n",
       "      <td>job_4e16e9830b072344</td>\n",
       "      <td>https://ie.indeed.com/rc/clk?jk=4e16e9830b0723...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>access healthcare, one of irelands leading hea...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                    id  \\\n",
       "0  assistant director of nursing   sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)   sj_358f1f68cde928c4   \n",
       "2               registered nurse  job_4e16e9830b072344   \n",
       "\n",
       "                                                link              date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...           unknown   \n",
       "2  https://ie.indeed.com/rc/clk?jk=4e16e9830b0723...  January 10, 2024   \n",
       "\n",
       "                                     job_description             label  \n",
       "0  silver stream healthcare group offer great emp...  registered_nurse  \n",
       "1  create a better future for yourself  recruitne...  registered_nurse  \n",
       "2  access healthcare, one of irelands leading hea...  registered_nurse  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the online job ads dataset and apply minor modifications for further use.\n",
    "df_jobads = pd.read_csv('data_jobads_final.csv', index_col=None)\n",
    "df_jobads['job_description'] = df_jobads['job_description'].str.replace('\\n', ' ')\n",
    "df_jobads = df_jobads.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"The shape of the joob ads' data frame is:\", df_jobads.shape)\n",
    "df_jobads.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second dataset consists of 1166 rows and 6 columns of data scraped from Indeed.com. The most essential column in this DF is the one with job descriptions. Similarly to the first DF, counting the words for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>registered nurse</td>\n",
       "      <td>job_4e16e9830b072344</td>\n",
       "      <td>https://ie.indeed.com/rc/clk?jk=4e16e9830b0723...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>access healthcare, one of irelands leading hea...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                    id  \\\n",
       "0  assistant director of nursing   sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)   sj_358f1f68cde928c4   \n",
       "2               registered nurse  job_4e16e9830b072344   \n",
       "\n",
       "                                                link              date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...           unknown   \n",
       "2  https://ie.indeed.com/rc/clk?jk=4e16e9830b0723...  January 10, 2024   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "1  create a better future for yourself  recruitne...  registered_nurse   \n",
       "2  access healthcare, one of irelands leading hea...  registered_nurse   \n",
       "\n",
       "   word_count  \n",
       "0         502  \n",
       "1         231  \n",
       "2         182  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobads['word_count'] = df_jobads['job_description'].apply(lambda x: len(x.split()))\n",
    "df_jobads.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All necessary libraries have been imported, and the datasets are also laoded and ready for use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. COSINE WITH FINE-TUNED BERT\n",
    "\n",
    "In this sub-section, the text columns from both DFs are fed into Bert's fine-tuned encoding layers, and the resulting text representations from the last hidden layer are collected for cosine similarity computation. For demonstration purposes, only one row value is used to retrieve the final hidden state. The remaining data is processed with a custom function that has been designed to handle different conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the text for demonstration to a variable.\n",
    "input_text_test = df_jobseeker.iat[0, -2]\n",
    "\n",
    "# Initialize a fine-tuned model with the hidden state output enabled.\n",
    "model = BertForSequenceClassification.from_pretrained('ft_bert_temuulen2', output_hidden_states=True)\n",
    "\n",
    "# Initialize a tokenizer used for the fine-tuned model.\n",
    "tokenizer = AutoTokenizer.from_pretrained('ft_bert_temuulen_tokenizer2')\n",
    "\n",
    "# Tokenize the input text and convert it to PyTorch tensors.\n",
    "inputs = tokenizer(input_text_test, return_tensors='pt')\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous cell, the test text specified for demonstration purposes was assigned to a variable and tokenized. The results were formatted as tensors to be compatible with our deep learning framework, PyTorch in this instance. The output of the cell shows that input itself consists of **input_ids** and **attention_mask** values, which are important for further procesing, as well as **token_type_ids** values, which are optional for the current context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a forward pass through the model to get the hidden states.\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract the last hidden states from the model outputs.\n",
    "last_hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "print('The size of the last hidden state tensor is:', last_hidden_states.shape, '\\n')\n",
    "print('The data type of the last hidden state tensor is:', type(last_hidden_states), '\\n')\n",
    "print(last_hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following tokenization, the input values were passed forward through the model, resulting in the extraction of a torch tensor representing hidden states with dimensions of ([1, 44, 768]). This tensor will then be used for cosine similarity calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **emplementation**\n",
    "\n",
    "The demonstration went well and the tensor was successfully extracted. Now lets begin the main implementation for both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize the model*\n",
    "\n",
    "The encoding model has been fine-tuned using the **bert-based-uncased** architecture for text sequence classification and was imported from the personal drive. The tokenizer employed is HuggingFace's autotokenizer, which automatically selects and pairs with the most suitable tokenizer for the model. In this instance, it is the **BertTokenizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a fine-tuned model with the hidden state output enabled.\n",
    "model = BertForSequenceClassification.from_pretrained('ft_bert_temuulen2', output_hidden_states=True)\n",
    "\n",
    "# Initialize a tokenizer used for the fine-tuned model.\n",
    "tokenizer = AutoTokenizer.from_pretrained('ft_bert_temuulen_tokenizer2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load the dataset*\n",
    "\n",
    "The dataset used in this implementation is a duplicate of the primary DFs containing information about job seekers and job advertisements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_js = df_jobseeker.copy()\n",
    "df_bert_ja = df_jobads.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize the gpu* (optional)\n",
    "\n",
    "To enhance the effectiveness of managing matrix and tensor operations, the CUDA device was created. This capability represents a key advantage of utilizing the BERT model within the Torch framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether CUDA is accessible and, if so, create a CUDA device.\n",
    "cuda_available = torch.cuda.is_available()\n",
    "cuda_device= torch.cuda.get_device_name(0)\n",
    "\n",
    "if cuda_available == True:\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA was successfully installed and compiled on my device.')\n",
    "    print('CUDA device name is:', cuda_device)\n",
    "else:\n",
    "    print('Cuda in not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the encoding process, it's essential to check the word count to ensure that it doesn't surpass 510, due to a constraint associated with the BERT model. If the word count exceed this threshold, it is necessary to formulate a new strategy for obtaining the encoded value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The total number of rows having word counts greater than 510 in the first DF is:', df_bert_js[df_bert_js['word_count'] > 510].shape[0])\n",
    "print('The total number of rows having word counts greater than 510 in the second DF is:', df_bert_ja[df_bert_ja['word_count'] > 510].shape[0])\n",
    "print('The word count for the longest text is:', df_bert_ja.iat[df_bert_ja['word_count'].idxmax(), -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*create custom function*\n",
    "\n",
    "From the output observed in the preceding cell, it is clear that the DF for job seekers does not contain entries exceeding the 510-word limit, allowing the definition of a standard custom function for tokenization and extraction of the last hidden state without additional conditions. Conversely, the DF for job advertisements contains 236 entries surpassing the 510-word threshold, with the longest text totaling 3145 words. To process these inputs through the model, a custom function incorporating special conditions must be developed and applied. The upcoming two custom functions are designed specifically for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to extract the final layer encodings from BERT, without conditions.\n",
    "def process_text(text):\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    \n",
    "    # Pass the tokenized input through the model.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Retrieve the last hidden states from the model's outputs.\n",
    "    last_hidden_states = outputs.hidden_states[-1]\n",
    "    \n",
    "    return last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to extract the final layer encodings from BERT, with conditions.\n",
    "def embed_with_bert(df_column):\n",
    "    \n",
    "    embedded_texts = []\n",
    "    \n",
    "    # Iterate through each text in the DataFrame column.\n",
    "    for text in df_column:\n",
    "        \n",
    "        # Tokenize each text without adding special tokens and without truncation or padding.\n",
    "        tokens = tokenizer(text, add_special_tokens=False, return_tensors='pt', truncation=False, padding=False)['input_ids'].squeeze()\n",
    "        token_length = len(tokens)\n",
    "        \n",
    "        # If the token length is less than or equal to 512, process it normally.\n",
    "        if token_length <= 512:\n",
    "            inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            last_hidden_states = outputs.hidden_states[-1].cpu()  \n",
    "            embedded_texts.append(last_hidden_states)\n",
    "            \n",
    "        # If the token length is greater than 512, split it into sliding windows withot lapping.\n",
    "        else:\n",
    "            max_length = 512\n",
    "            stride = 0\n",
    "            tokens = tokenizer(text, add_special_tokens=False, return_tensors='pt', truncation=False, padding=False)['input_ids'].squeeze().to(device)\n",
    "            token_windows = [tokens[i:i+max_length] for i in range(0, len(tokens), max_length - stride)]\n",
    "            \n",
    "            all_hidden_states = []\n",
    "            \n",
    "            # Add special tokens (CLS and SEP) and truncate if needed.\n",
    "            for window in token_windows:\n",
    "                window = torch.cat([torch.tensor([tokenizer.cls_token_id], device=device), window, torch.tensor([tokenizer.sep_token_id], device=device)])\n",
    "                if len(window) > max_length:\n",
    "                    window = torch.cat((window[:max_length-1], torch.tensor([tokenizer.sep_token_id], device=device)))\n",
    "                inputs = {'input_ids': window.unsqueeze(0)}\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                hidden_states = outputs.hidden_states[-1].cpu()  \n",
    "                all_hidden_states.append(hidden_states)\n",
    "            \n",
    "            # Concatenate all hidden states from each sliding window.\n",
    "            embedded_texts.append(torch.cat(all_hidden_states, dim=1))\n",
    "            \n",
    "    return embedded_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*encode the text*\n",
    "\n",
    "Using the custom functions created earlier to process each DF and extract the tensor of the final hidden state layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function and create a new column with the extracted results.\n",
    "df_bert_js['last_layer'] = df_bert_js.iloc[:, -2].apply(process_text)\n",
    "\n",
    "print('The shape of the first tensor:', df_bert_js.iat[0, -1].shape, '\\n')\n",
    "print('The shape of the second tensor:', df_bert_js.iat[1, -1].shape, '\\n')\n",
    "print('The shape of the third tensor:', df_bert_js.iat[2, -1].shape, '\\n')\n",
    "print(df_bert_js.iat[0, -1], '\\n')\n",
    "\n",
    "# Check the Data Frame.\n",
    "df_bert_js.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the GPU.\n",
    "model.to(device)\n",
    "\n",
    "# Apply the 'embed_with_bert' function to each ad.\n",
    "df_bert_ja['tensors'] = df_bert_ja['job_description'].apply(lambda x: embed_with_bert([x])[0])\n",
    "\n",
    "# Check the random cell to see the results.\n",
    "print(df_bert_ja.iat[0, -1].shape, '\\n')\n",
    "print(df_bert_ja.iat[0, -1], '\\n')\n",
    "\n",
    "# Check the Data Frame.\n",
    "df_bert_ja.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the previous cells indicate that the tensors generated by processing each text entry from the 'combined_info' column through the encoding layers of the fine-tuned models maintain consistent dimensions in the first and third positions. This consistency is due to the fact that each encoder handles a single sample at a time, with a batch size of one, and represents each token in the text with a 768-feature vector. However, the number of tokens in the second dimensions, representing each text, varies and slightly exceeds the actual word count of each text. This variability is because of the WordPiece tokenization approach used by the BERT model, which breaks down words into smaller pieces if they are not present in the tokenizer's lexicon. This approach enables the model to more effectively manage unrecognized words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*calculate cosine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costum function that generates the evarage cosine similarity between the user's tensor and a job ad's tensor.\n",
    "def calculate_average_similarity(tensor_user, tensor_ad):\n",
    "    \n",
    "    # Squeeze dimensions if the tensors have a batch dimension.\n",
    "    tensor_user = tensor_user.squeeze(0) if tensor_user.dim() == 3 else tensor_user\n",
    "    tensor_ad = tensor_ad.squeeze(0) if tensor_ad.dim() == 3 else tensor_ad\n",
    "\n",
    "    tensor_ad = tensor_ad.to(tensor_user.device)\n",
    "\n",
    "    # Initialize a similarity matrix with zeros.\n",
    "    similarity_matrix = torch.zeros(tensor_user.size(0), tensor_ad.size(0), device=tensor_user.device)\n",
    "    \n",
    "    # Calculate cosine similarity for each pair of vectors.\n",
    "    for i in range(tensor_user.size(0)):\n",
    "        for j in range(tensor_ad.size(0)):\n",
    "            similarity_matrix[i, j] = F.cosine_similarity(tensor_user[i].unsqueeze(0), tensor_ad[j].unsqueeze(0), dim=1)\n",
    "            \n",
    "    # Calculate the average similarity and convert it to a Python float.\n",
    "    average_similarity = torch.mean(similarity_matrix).item()\n",
    "    \n",
    "    return average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The cosine similarity between the texts from user1 and user2 is:', calculate_average_similarity(df_bert_js.iat[0, -1], df_bert_js.iat[1, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the user1's tensor and move it to the GPU.\n",
    "user1_tensor = df_bert_js.iat[0, -1]\n",
    "user1_tensor = user1_tensor.to(device)\n",
    "\n",
    "# Get the user2's tensor and move it to the GPU.\n",
    "user2_tensor = df_bert_js.iat[1, -1]\n",
    "user2_tensor = user2_tensor.to(device)\n",
    "\n",
    "# Get the user3's tensor and move it to the GPU.\n",
    "user3_tensor = df_bert_js.iat[2, -1]\n",
    "user3_tensor = user3_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the calculation of average cosine similarity function to each job ad's tensor.\n",
    "df_bert_ja['cosine_user1'] = df_bert_ja.iloc[:, -1].apply(lambda x: calculate_average_similarity(user1_tensor, x.to(device)))\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the calculation of average cosine similarity function to each job ad's tensor.\n",
    "df_bert_ja['cosine_user2'] = df_bert_ja.iloc[:, -2].apply(lambda x: calculate_average_similarity(user2_tensor, x.to(device)))\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the calculation of average cosine similarity function to each job ad's tensor.\n",
    "df_bert_ja['cosine_user3'] = df_bert_ja.iloc[:, -3].apply(lambda x: calculate_average_similarity(user3_tensor, x.to(device)))\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the encoded column from the Data Frame (it takes up too much memory and is no longer needed).\n",
    "df_bert_ja = df_bert_ja.drop(columns=['tensors']) \n",
    "\n",
    "df_bert_ja.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_ja.to_csv('cosine-bert.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "\n",
    "print(f'The calculation of cosine similarity score using fine-tuned Bert model was completed in: {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COSINE WITH PRE-TRAINED WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Word2Vec model\n",
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word2vec_js = df_jobseeker.copy()\n",
    "df_word2vec_ja = df_jobads.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing and tokenizing\n",
    "def preprocess_text_word2vec(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Removing punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word2vec_js['processed_ci'] = df_word2vec_js['combined_info'].apply(preprocess_text_word2vec)\n",
    "df_word2vec_ja['processed_jd'] = df_word2vec_ja['job_description'].apply(preprocess_text_word2vec)\n",
    "\n",
    "df_word2vec_js.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For each entry in text column, the custom function tokenizes the text into words. Then it filters out the words not in the Word2Vec vocabulary, and then generate embeddings for each word. A common approach is to average these word vectors to get a single vector that represents the entire text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*embedding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_tokens(tokens_list, model):\n",
    "    vectors = [model[word] for word in tokens_list if word in model]\n",
    "    if vectors:\n",
    "        # Averaging the vectors (You could choose another aggregation method)\n",
    "        embedding = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        # Use a zero vector if none of the tokens were found in the Word2Vec model\n",
    "        embedding = np.zeros(model.vector_size)\n",
    "        \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to embed each row's tokens in the DataFrame\n",
    "df_word2vec_js['vectors'] = df_word2vec_js['processed_ci'].apply(lambda x: embed_tokens(x, word2vec))\n",
    "df_word2vec_ja['vectors'] = df_word2vec_ja['processed_jd'].apply(lambda x: embed_tokens(x, word2vec))\n",
    "# This will add a new column 'word2vec_embedding' where each row contains the aggregated Word2Vec embedding for its tokens\n",
    "\n",
    "print('The shape of the first tensor:', df_word2vec_js.iat[0, -1].shape, '\\n')\n",
    "print('The shape of the second tensor:', df_word2vec_js.iat[1, -1].shape, '\\n')\n",
    "print(df_word2vec_js.iat[0, -1], '\\n')\n",
    "\n",
    "df_word2vec_ja.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate cosine similarity (dot product in this case)\n",
    "def cos(vector1, vector2):\n",
    "    return np.dot(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1_vector = df_word2vec_js.iat[0, -1].copy()\n",
    "user2_vector = df_word2vec_js.iat[1, -1].copy()\n",
    "user3_vector = df_word2vec_js.iat[2, -1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity for each row\n",
    "df_word2vec_ja['cos_user1'] = df_word2vec_ja['vectors'].apply(lambda x: cos(x, user1_vector))\n",
    "\n",
    "df_word2vec_ja['cos_user2'] = df_word2vec_ja['vectors'].apply(lambda x: cos(x, user2_vector))\n",
    "\n",
    "df_word2vec_ja['cos_user3'] = df_word2vec_ja['vectors'].apply(lambda x: cos(x, user3_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word2vec_ja.drop(columns=['processed_jd', 'vectors'], inplace=True)\n",
    "\n",
    "df_word2vec_ja.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word2vec_ja.to_csv('cosine-word2vec.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "\n",
    "print(f'The calculation was completed in: {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')\n",
    "\n",
    "print(f'The calculation of cosine similarity using pretrained word2vec model was completed in: {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COSINE WITH TF-IDF AND BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize the tools*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "bow_vectorizer = CountVectorizer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf_js = df_jobseeker.copy()\n",
    "df_tfidf_ja = df_jobads.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_tfidf(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Removing punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Removing stopwords and lemmatization\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    # Re-joining tokens\n",
    "    processed_text = ' '.join(processed_tokens)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>preferred_position</th>\n",
       "      <th>combined_info</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-17 15:30:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>bachelor's degree: critical care nursing. pati...</td>\n",
       "      <td>27</td>\n",
       "      <td>bachelor degree critical care nursing patient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-27 11:50:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>electrician</td>\n",
       "      <td>high school diploma, vocational electrician ce...</td>\n",
       "      <td>33</td>\n",
       "      <td>high school diploma vocational electrician cer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant data_collection                 date         location  \\\n",
       "0      user_1      voice call  2023-12-17 15:30:00  dublin, ireland   \n",
       "1      user_2      voice call  2023-12-27 11:50:00  dublin, ireland   \n",
       "\n",
       "  preferred_position                                      combined_info  \\\n",
       "0   registered nurse  bachelor's degree: critical care nursing. pati...   \n",
       "1        electrician  high school diploma, vocational electrician ce...   \n",
       "\n",
       "   word_count                                       processed_ci  \n",
       "0          27  bachelor degree critical care nursing patient ...  \n",
       "1          33  high school diploma vocational electrician cer...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf_js['processed_ci'] = df_tfidf_js['combined_info'].apply(preprocess_text_tfidf)\n",
    "df_tfidf_ja['processed_jd'] = df_tfidf_ja['job_description'].apply(preprocess_text_tfidf)\n",
    "df_tfidf_js.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_jd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "\n",
       "                                                link              date  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "\n",
       "  word_count                                       processed_jd  \n",
       "0                                                                \n",
       "1                                                                \n",
       "2                                                                \n",
       "3        502  silver stream healthcare group offer great emp...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_rows = pd.DataFrame([[''] * len(df_tfidf_ja.columns)] * 3, columns=df_tfidf_ja.columns)\n",
    "df_tfidf_ja = pd.concat([empty_rows, df_tfidf_ja], ignore_index=True)\n",
    "\n",
    "df_tfidf_ja.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_jd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>bachelor degree critical care nursing patient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>high school diploma vocational electrician cer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>degree master science data analytics bachelor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "\n",
       "                                                link              date  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "\n",
       "  word_count                                       processed_jd  \n",
       "0             bachelor degree critical care nursing patient ...  \n",
       "1             high school diploma vocational electrician cer...  \n",
       "2             degree master science data analytics bachelor ...  \n",
       "3        502  silver stream healthcare group offer great emp...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_to_add = df_tfidf_js['processed_ci'].tolist()[:3]\n",
    "df_tfidf_ja['processed_jd'].iloc[:3] = values_to_add\n",
    "\n",
    "df_tfidf_ja.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_jd</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>bachelor degree critical care nursing patient ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>high school diploma vocational electrician cer...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>degree master science data analytics bachelor ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>[0.0, 0.0, 0.04749643991878368, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "\n",
       "                                                link              date  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "\n",
       "  word_count                                       processed_jd  \\\n",
       "0             bachelor degree critical care nursing patient ...   \n",
       "1             high school diploma vocational electrician cer...   \n",
       "2             degree master science data analytics bachelor ...   \n",
       "3        502  silver stream healthcare group offer great emp...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.04749643991878368, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_tfidf_ja['processed_jd'])\n",
    "bow_matrix = bow_vectorizer.fit_transform(df_tfidf_ja['processed_jd'])\n",
    "combined_matrix = hstack([tfidf_matrix, bow_matrix])\n",
    "\n",
    "# Convert each row of the TF-IDF matrix to a list and store in a new DataFrame column\n",
    "df_tfidf_ja['vectors'] = list(combined_matrix.toarray())\n",
    "df_tfidf_ja.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20162,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "check_df = df_tfidf_ja.iat[0, -1]\n",
    "print(check_df.shape)\n",
    "print(type(check_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20152</th>\n",
       "      <th>20153</th>\n",
       "      <th>20154</th>\n",
       "      <th>20155</th>\n",
       "      <th>20156</th>\n",
       "      <th>20157</th>\n",
       "      <th>20158</th>\n",
       "      <th>20159</th>\n",
       "      <th>20160</th>\n",
       "      <th>20161</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows  20162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1         2      3      4      5      6      7      8      9      \\\n",
       "0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3    0.0    0.0  0.047496    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   ...  20152  20153  20154  20155  20156  20157  20158  20159  20160  20161  \n",
       "0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[4 rows x 20162 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_array = pd.DataFrame(df_tfidf_ja['vectors'].tolist())\n",
    "vectors_array.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00959848, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_vectors = normalize(vectors_array, norm='l2', axis=1)\n",
    "normalized_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_jd</th>\n",
       "      <th>vectors</th>\n",
       "      <th>normolized_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>bachelor degree critical care nursing patient ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>high school diploma vocational electrician cer...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>degree master science data analytics bachelor ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>[0.0, 0.0, 0.04749643991878368, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0016647493576457985, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "\n",
       "                                                link              date  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "\n",
       "  word_count                                       processed_jd  \\\n",
       "0             bachelor degree critical care nursing patient ...   \n",
       "1             high school diploma vocational electrician cer...   \n",
       "2             degree master science data analytics bachelor ...   \n",
       "3        502  silver stream healthcare group offer great emp...   \n",
       "\n",
       "                                             vectors  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.04749643991878368, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                      normolized_vec  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0016647493576457985, 0.0, 0.0, 0....  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf_ja['normolized_vec'] = normalized_vectors.tolist()\n",
    "df_tfidf_ja.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cosine calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1169, 20162)\n",
      "(1, 20162)\n"
     ]
    }
   ],
   "source": [
    "vectors_tf = np.array(df_tfidf_ja['normolized_vec'].tolist()).copy()\n",
    "\n",
    "user1_vector_tf = vectors_tf[0].reshape(1, -1).copy()\n",
    "user2_vector_tf = vectors_tf[1].reshape(1, -1).copy()\n",
    "user3_vector_tf = vectors_tf[2].reshape(1, -1).copy()\n",
    "\n",
    "print(vectors_tf.shape)\n",
    "print(user1_vector_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = cos(user1_vector_tf, vectors_tf).flatten()\n",
    "df_tfidf_ja['cos_user1'] = cosine_similarities\n",
    "\n",
    "cosine_similarities = cos(user2_vector_tf, vectors_tf).flatten()\n",
    "df_tfidf_ja['cos_user2'] = cosine_similarities\n",
    "\n",
    "cosine_similarities = cos(user3_vector_tf, vectors_tf).flatten()\n",
    "df_tfidf_ja['cos_user3'] = cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cos_user1</th>\n",
       "      <th>cos_user2</th>\n",
       "      <th>cos_user3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>0.301457</td>\n",
       "      <td>0.022477</td>\n",
       "      <td>0.033491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>231</td>\n",
       "      <td>0.301988</td>\n",
       "      <td>0.037650</td>\n",
       "      <td>0.005109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)  sj_358f1f68cde928c4   \n",
       "\n",
       "                                                link              date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...           unknown   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "1  create a better future for yourself  recruitne...  registered_nurse   \n",
       "\n",
       "  word_count  cos_user1  cos_user2  cos_user3  \n",
       "0        502   0.301457   0.022477   0.033491  \n",
       "1        231   0.301988   0.037650   0.005109  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing the DataFrame to exclude the first three rows\n",
    "df_tfidf_ja = df_tfidf_ja.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "df_tfidf_ja.drop(columns=['processed_jd', 'vectors', 'normolized_vec'], inplace=True)\n",
    "\n",
    "df_tfidf_ja.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf_ja.to_csv('cosine-tfidf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculation of cosine similarity using TF-IDF and BoW was completed in: 1 minutes and 13 seconds.\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "\n",
    "print(f'The calculation of cosine similarity using TF-IDF and BoW was completed in: {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
